services:
  mongo:
    image: mongo:6
    restart: unless-stopped
    ports: ["27017:27017"]
    volumes: [ "mongo_data:/data/db" ]

  qdrant:
    image: qdrant/qdrant:latest
    restart: unless-stopped
    ports: ["6333:6333"]
    volumes: [ "qdrant_data:/qdrant/storage" ]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/healthz" ]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    ports: ["11434:11434"]
    command: serve
    # ðŸ‘‡ THIS IS THE LINE THAT PROTECTS YOUR MODELS ðŸ‘‡
    volumes: [ "ollama:/root/.ollama" ]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags" ]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s

  rag-api:
    build: .
    depends_on:
      mongo:
        condition: service_started
      qdrant:
        condition: service_started
      ollama:
        condition: service_started
    env_file: .env
    volumes: [".:/app"]
    ports: ["8000:8000"]
    command: ["uvicorn", "chat.chat_api:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

  streamlit-ui:
    build: .
    depends_on:
      - rag-api
    env_file: .env
    volumes: [".:/app"]
    ports: ["8501:8501"]
    command: ["streamlit", "run", "streamlit_app.py", "--server.port", "8501", "--server.address", "0.0.0.0"]

volumes:
  mongo_data:
  qdrant_data:
  ollama: